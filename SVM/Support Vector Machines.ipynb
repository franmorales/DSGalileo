{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machines es un algoritmo de clasificacion, basicamente lo que busca es la mejor manera de separar la data. Para ellos, hacemos uso del concepto de frontera de decision. En nuestro caso para SVM utilizamos la frontera de decision con cierto margen entre la frontera que divide a un grupo de otro.\n",
    "\n",
    "INSERTE PRIMERA IMAGEN AQUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este margen se puede definir de la siguiente manera: La distancia entre el vector de soporte y la las lineas que forman la frontera es tan grande como sea posible.\n",
    "\n",
    "\n",
    "Como maximizamos el margen que conforma la frontera? Este es un problema de optimizacion con restricciones (Constrained optimization problem). \n",
    "\n",
    "* Limitacion: Los puntos al final de los vectores de soporte no pueden estar dentro del margen de frontera. \n",
    "* Optimizacion: El margen de frontera debe ser tan grande como sea posible.\n",
    "\n",
    "*Como optimizamos esto?* \n",
    "\n",
    "Para este caso, utlizamos Multiplicadores de Lagrange \n",
    "\n",
    "\n",
    "1. Buscar/adquirir la data \n",
    "2. Aplicar un model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametro C: Que pasa cuando tenenomos un ejemplo que se sale del orden de clasificacion (missclasification)\n",
    "\n",
    "Paramtro C: Que tanto se tiene que penalizar este tipo de error de clasificacion. El parametro default para el parametro C es uno.\n",
    "\n",
    "\n",
    "Low C: Prioritize simplicity\n",
    "\n",
    "High C: Prioriteze makeing few mistakes (overfitting). Esto es un hiperparametro.\n",
    "\n",
    "**Que pasa si necesitamos mas de dos clases? Funciona?**\n",
    "\n",
    "Si, pero la frontera de decision es unicamente lineas. (para fronteras de decision mas complejas, debemos utilizar feature engineering).\n",
    "\n",
    "Cuando se trata de un problema de clasificacion que no es binario (cuando el resultado de la clasificacion no es una variable dicotomica). Se pueden utilizar dos tipos de tecnicas: \n",
    "\n",
    "* One vs Rest\n",
    "* One vs One\n",
    "\n",
    "## Kernel trick: Visual \n",
    "\n",
    "Para fronteras de decision no lineales.  Lo que hace es agregar otra dimension a la data, para tratar de poder trazar una frontera de division a travez de un hiperplano que si pueda realizar la clasificacion con una frontera de decision lineal\n",
    "\n",
    "**Otro hiperparametro** Gamma value: A mayor gamma, mayor complejidad, por tanto se corre riesgo de overfitting.\n",
    "\n",
    "## Pros and Cons of SVM:\n",
    "\n",
    "* Pros:\n",
    "1. Good at dealing with high demensional data\n",
    "2. Works well on samll data sets\n",
    "\n",
    "* Cons:\n",
    "\n",
    "1. Picking the right kernel and parameters can be computationally intensive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################\n",
    "\n",
    "# Aqui comienza la parte que yo hago, Maydelin por favor ver desde aqui\n",
    "\n",
    "\n",
    "# Prediccion/Inferencias:\n",
    "\n",
    "Dado que es un algoritmo de clasificacion, su metodologia de inferencias se basa en establecer fronteras de decision  sobre toda la data:\n",
    "\n",
    "<img src=\"edgeDecision.png\">\n",
    "\n",
    "Su meta principal es la de crear la mejor linea (o hiperplano) que logre dividir mejor la data para una mejor clasificacion. Para ello, ademas de utlizar la clasica divsion de la frontera de decision, se apoya en lo que se conoce como vectores de soporte, que no son mas que dos lineas (o hiperplanos) adicionales a cada lado del principal. Estos vectores se construyen a partir de los elementos mas cercanos a la frontera de decision, en ambas clases (para este ejemplo, los perritos y gatitos mas cercanos a la frontera de decision):\n",
    "\n",
    "<img src=\"supportVectors.png\">\n",
    "\n",
    "\n",
    "Tambien se basa en Cross Validation - K Folds\n",
    "\n",
    "\n",
    "# Ventajas y desventajas:\n",
    "\n",
    "Ventajas:\n",
    "* Es un algoritmo capaz de ser utilizado con poca data.\n",
    "* Es capaz de reconocer fronteras de desición no lineales y con formas mas complejas, sin necesidad de recurrir a Feature Engineering. Esto lo logra a traves de sobredimensionar los datos (Kernel Trick). \n",
    "\n",
    "<img src=\"overDimensions.png\">\n",
    "\n",
    "* Debido a que es un modelo parametrico, provee de flexibilidad al momento de poder \"jugar\" con el diseno del modelo.\n",
    "\n",
    "Desventajas: \n",
    "\n",
    "* Debido a la implementacion del Kernel Trick, tambien se tiene que utilizar mas recursos computacionales.\n",
    "* Bajo desempeño cuando el numero de Features es mayor que el numero de muestras.\n",
    "* No probee distribuciones de probabilidad.\n",
    "\n",
    "# Diferencias:\n",
    "\n",
    "Una de las principales diferencias entre este metodo de clasificacion y el de KNN visto en clase, es que éste es **un metodo parametrico** por lo que si requiere de un proceso de entrenamiento. \n",
    "\n",
    "Contrario al algoritmo de regresion logistica (otro modelo de clasificación que si es parametrico), este modelo no nos brinda una distribucion de probabilidad en cuanto al valor de la variable a predecir. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliografias:\n",
    "    \n",
    "https://www.youtube.com/watch?v=Y6RRHw9uN9o\n",
    "\n",
    "\n",
    "https://www.youtube.com/watch?v=N1vOgolbjSc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation: (ESTO NO VA EN LA TAREA)\n",
    "\n",
    "Resuelve un problema relacionado a que parte del porcentaje de la data debemos utilizar para testing y para training, **no es que nos diga que porcentaje, sino mas bien, que parte de la data vamos a adaptar a ese porcentaje** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
