{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FFZyOKmYGFGp",
    "outputId": "4ec14141-7a23-4996-959d-64ac6ee2a543"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Librerias backend:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "# Librerias frontend:\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, Flatten, MaxPooling2D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_UhM4zk9B-1"
   },
   "source": [
    "# Presentacion del dataset y objetivo de la convnet:\n",
    "\n",
    "Se tiene un dataset contiendo imagenes de 16 piezas de lego distintas. El objetivo es lograr predecir al nombre de la pieza mostrada en la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omrlJYahHdsg"
   },
   "outputs": [],
   "source": [
    "#plt.imshow(\"/content/drive/My Drive/MLII/CNN/LEGO brick images/train/11214 Bush 3M friction with Cross axle/201706171006-0001.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YDCvHaU-JcTj"
   },
   "source": [
    "Para la implementacion del modelo se utilizará Keras, dada la simplicidad de implementacion y la flexibilidad en cuanto a la eleccion de la arquitectura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z6P4eRe1G6tP"
   },
   "source": [
    "# Architectura de la CNN:\n",
    "\n",
    "Se tomaran en cuenta las recomendaciones hechas en clase:\n",
    "\n",
    "* Se utilizara la funcion de activacion ReLu.\n",
    "* Se Utilizará Max Pooling (lo que hay \"mas importante\")\n",
    "* No se utiizará **dropaut**\n",
    "* Dado que el dataset consiste en imagenes renderizadas de piezas de lego rotadas, se evaluará la opcion de realizar aumentado de datos.\n",
    "* Se utilizará el optimizador Adam \n",
    "* Se utilizará un batch size de 64\n",
    "\n",
    "Las imagenes tiene un tamaño estandard de 72x72, siendo cada una de 3 canalaes. Por lo tanto, mi capa de entrada será de: 72x72x3.\n",
    "\n",
    "La capa convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R9DTJxOkJrvY"
   },
   "source": [
    "# Carga del dataset y preprocesamiento de las imagenes.\n",
    "\n",
    "Fuente: https://keras.io/preprocessing/image/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TjUp_T11GXh"
   },
   "outputs": [],
   "source": [
    "imageWidth = 72\n",
    "imageHeight = 72 \n",
    "imageChannel = 3\n",
    "testPorcen = 0.15\n",
    "batchSize = 16\n",
    "dataPath = 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2SFJDVp3dB7"
   },
   "source": [
    "Declaracion del generador para preprocesar las imagenes. Se tomara un 15% de datos para test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1IkrTF21Bed"
   },
   "outputs": [],
   "source": [
    "#Se utilizaran los valores por defecto de la generador:\n",
    "train_datagen = ImageDataGenerator(\n",
    "        validation_split=testPorcen, #Split argument for data division.\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ewd4VI1w3AJ-"
   },
   "source": [
    "Procedemos con la separacion de la data en Train y Test. **Debido a que especificamos el valor de validation_split en el generador anterior, ahora debemos especificar que datos son de validacion (test) y cuales son de train.**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "045x5Io83Oia",
    "outputId": "9aaa65f6-bec1-44ae-892f-f24149aa109f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5423 images belonging to 16 classes.\n",
      "Found 956 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        dataPath,\n",
    "        target_size=(imageHeight, imageWidth),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical', #Por defecto es categorical, sin embargo, no esta de más settearla manualmente.\n",
    "        subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        dataPath,\n",
    "        target_size=(imageHeight, imageWidth),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical', #Por defecto es categorical, sin embargo, no esta de más settearla manualmente.\n",
    "        subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ZBZCn4wEmQ5"
   },
   "source": [
    "Procedemos a aplicar los generadores para obtener nuestra deta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bm176I6Lknwo"
   },
   "source": [
    "# Creacion del modelo:\n",
    "\n",
    "Fuente: https://towardsdatascience.com/boost-your-cnn-image-classifier-performance-with-progressive-resizing-in-keras-a7d96da06e20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CbhpH0m2oKTI"
   },
   "outputs": [],
   "source": [
    "#Valores de la capa convolucional:\n",
    "filtersNumber = 32\n",
    "filterSize = 3\n",
    "pool_size = 3\n",
    "fully_connected_neurons = 64\n",
    "drop_out_factor = 0.6\n",
    "classes_out = 16 #numero de tipos de legos (neuronas de salida.)\n",
    "numEpochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "colab_type": "code",
    "id": "_JC54NJxpzl5",
    "outputId": "032a4e74-299c-4241-c815-bc23e554c41a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/FranciscoMorales/anaconda3/envs/tensor_flow_cpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/FranciscoMorales/anaconda3/envs/tensor_flow_cpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 70, 70, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 21, 21, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 54,048\n",
      "Trainable params: 54,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#Primera capa de convolución (se estan tomando en cuenta todas las recomendaciones indicadas: Funcion de activacion Relu, Mini Batch de 64)\n",
    "model.add(Conv2D(batchSize, input_shape=(imageHeight, imageWidth, imageChannel) , activation='relu', kernel_size=(filterSize, filterSize)  ))\n",
    "#Pooling, tomando en cuenta la recomendacion de utilizar MaxPooling:\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "\n",
    "#Segunda capa de convolucion:\n",
    "model.add(Conv2D(batchSize, input_shape=(imageHeight, imageWidth, imageChannel) , activation='relu', kernel_size=(filterSize, filterSize)  ))\n",
    "#Pooling para la segunda capa:\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "\n",
    "#Aplanado de la ultima capa de pooling con las respectivas caracteristicas para la parte \"fully connected\":\n",
    "model.add(Flatten())\n",
    "#Se utilizaran 64 neuronas en la etapa fully connected\n",
    "model.add(Dense(fully_connected_neurons, activation='relu'))\n",
    "#En esta etapa si se utilizará dropout, ya que equivale a un modelo MLP:\n",
    "model.add(Dropout(rate=drop_out_factor))\n",
    "#Se tienen 16 neuronas de salida, 1 para cada posible valor de la salida. Se utiliza Softmax puesto que necesitamos una probabiliad\n",
    "model.add(Dense(classes_out, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "bpeCrm6puMEx",
    "outputId": "491b9601-f637-4272-c450-eb739367f657"
   },
   "outputs": [],
   "source": [
    "#Compilando el modelo:\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 828
    },
    "colab_type": "code",
    "id": "CEawH8cvylD5",
    "outputId": "b1361ab8-db07-4075-f231-8caf8eafa09c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/FranciscoMorales/anaconda3/envs/tensor_flow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "338/338 [==============================] - 29s 87ms/step - loss: 2.2915 - acc: 0.2218 - val_loss: 1.7613 - val_acc: 0.3550\n",
      "Epoch 2/50\n",
      "338/338 [==============================] - 30s 87ms/step - loss: 1.8401 - acc: 0.3464 - val_loss: 1.5165 - val_acc: 0.3876\n",
      "Epoch 3/50\n",
      "338/338 [==============================] - 30s 88ms/step - loss: 1.6566 - acc: 0.3925 - val_loss: 1.4127 - val_acc: 0.4373\n",
      "Epoch 4/50\n",
      "338/338 [==============================] - 29s 86ms/step - loss: 1.5160 - acc: 0.4405 - val_loss: 1.3004 - val_acc: 0.4682\n",
      "Epoch 5/50\n",
      "338/338 [==============================] - 31s 91ms/step - loss: 1.4478 - acc: 0.4590 - val_loss: 1.2644 - val_acc: 0.4716\n",
      "Epoch 6/50\n",
      "338/338 [==============================] - 30s 89ms/step - loss: 1.4096 - acc: 0.4683 - val_loss: 1.2769 - val_acc: 0.4733\n",
      "Epoch 7/50\n",
      "338/338 [==============================] - 31s 91ms/step - loss: 1.3227 - acc: 0.4942 - val_loss: 1.2146 - val_acc: 0.5301\n",
      "Epoch 8/50\n",
      "338/338 [==============================] - 31s 91ms/step - loss: 1.3019 - acc: 0.5088 - val_loss: 1.1896 - val_acc: 0.5091\n",
      "Epoch 9/50\n",
      "338/338 [==============================] - 30s 87ms/step - loss: 1.2511 - acc: 0.5280 - val_loss: 1.0985 - val_acc: 0.5943\n",
      "Epoch 10/50\n",
      "338/338 [==============================] - 31s 91ms/step - loss: 1.2069 - acc: 0.5350 - val_loss: 1.1159 - val_acc: 0.5841\n",
      "Epoch 11/50\n",
      "338/338 [==============================] - 30s 90ms/step - loss: 1.1954 - acc: 0.5358 - val_loss: 1.1387 - val_acc: 0.5666\n",
      "Epoch 12/50\n",
      "338/338 [==============================] - 32s 94ms/step - loss: 1.1840 - acc: 0.5469 - val_loss: 1.0591 - val_acc: 0.5958\n",
      "Epoch 13/50\n",
      "338/338 [==============================] - 30s 89ms/step - loss: 1.1300 - acc: 0.5676 - val_loss: 0.9995 - val_acc: 0.6101\n",
      "Epoch 14/50\n",
      "338/338 [==============================] - 31s 92ms/step - loss: 1.1114 - acc: 0.5774 - val_loss: 0.9838 - val_acc: 0.6255\n",
      "Epoch 15/50\n",
      "338/338 [==============================] - 33s 97ms/step - loss: 1.0855 - acc: 0.5870 - val_loss: 0.9948 - val_acc: 0.6285\n",
      "Epoch 16/50\n",
      "338/338 [==============================] - 36s 106ms/step - loss: 1.0461 - acc: 0.6073 - val_loss: 0.9518 - val_acc: 0.6311\n",
      "Epoch 17/50\n",
      "338/338 [==============================] - 38s 113ms/step - loss: 1.0484 - acc: 0.6049 - val_loss: 0.9155 - val_acc: 0.6474\n",
      "Epoch 18/50\n",
      "338/338 [==============================] - 36s 105ms/step - loss: 1.0206 - acc: 0.6153 - val_loss: 0.8365 - val_acc: 0.6969\n",
      "Epoch 19/50\n",
      "338/338 [==============================] - 32s 96ms/step - loss: 1.0115 - acc: 0.6192 - val_loss: 0.8728 - val_acc: 0.6551\n",
      "Epoch 20/50\n",
      "338/338 [==============================] - 31s 93ms/step - loss: 0.9919 - acc: 0.6192 - val_loss: 0.8440 - val_acc: 0.6713\n",
      "Epoch 21/50\n",
      "338/338 [==============================] - 31s 91ms/step - loss: 0.9550 - acc: 0.6362 - val_loss: 0.9043 - val_acc: 0.6415\n",
      "Epoch 22/50\n",
      "338/338 [==============================] - 31s 92ms/step - loss: 0.9561 - acc: 0.6362 - val_loss: 0.8366 - val_acc: 0.6691\n",
      "Epoch 23/50\n",
      "338/338 [==============================] - 32s 94ms/step - loss: 0.9364 - acc: 0.6369 - val_loss: 0.8191 - val_acc: 0.6748\n",
      "Epoch 24/50\n",
      "338/338 [==============================] - 32s 95ms/step - loss: 0.9218 - acc: 0.6449 - val_loss: 0.9584 - val_acc: 0.5986\n",
      "Epoch 25/50\n",
      "338/338 [==============================] - 33s 98ms/step - loss: 0.8933 - acc: 0.6565 - val_loss: 0.7784 - val_acc: 0.6965\n",
      "Epoch 26/50\n",
      "338/338 [==============================] - 32s 96ms/step - loss: 0.8970 - acc: 0.6479 - val_loss: 0.7717 - val_acc: 0.7028\n",
      "Epoch 27/50\n",
      "338/338 [==============================] - 33s 97ms/step - loss: 0.8889 - acc: 0.6628 - val_loss: 0.7598 - val_acc: 0.7095\n",
      "Epoch 28/50\n",
      "338/338 [==============================] - 33s 99ms/step - loss: 0.8730 - acc: 0.6616 - val_loss: 0.7263 - val_acc: 0.7320\n",
      "Epoch 29/50\n",
      "338/338 [==============================] - 33s 97ms/step - loss: 0.8399 - acc: 0.6771 - val_loss: 0.7626 - val_acc: 0.7112\n",
      "Epoch 30/50\n",
      "338/338 [==============================] - 33s 98ms/step - loss: 0.8531 - acc: 0.6746 - val_loss: 0.6789 - val_acc: 0.7422\n",
      "Epoch 31/50\n",
      "338/338 [==============================] - 33s 97ms/step - loss: 0.8410 - acc: 0.6766 - val_loss: 0.7475 - val_acc: 0.7058\n",
      "Epoch 32/50\n",
      "338/338 [==============================] - 33s 97ms/step - loss: 0.8256 - acc: 0.6835 - val_loss: 0.8050 - val_acc: 0.6770\n",
      "Epoch 33/50\n",
      "338/338 [==============================] - 32s 96ms/step - loss: 0.8062 - acc: 0.6900 - val_loss: 0.6826 - val_acc: 0.7459\n",
      "Epoch 34/50\n",
      "338/338 [==============================] - 34s 100ms/step - loss: 0.8013 - acc: 0.6880 - val_loss: 0.7520 - val_acc: 0.6991\n",
      "Epoch 35/50\n",
      "338/338 [==============================] - 33s 97ms/step - loss: 0.8001 - acc: 0.6887 - val_loss: 0.6806 - val_acc: 0.7478\n",
      "Epoch 36/50\n",
      "338/338 [==============================] - 34s 100ms/step - loss: 0.7798 - acc: 0.7006 - val_loss: 0.6591 - val_acc: 0.7491\n",
      "Epoch 37/50\n",
      "338/338 [==============================] - 34s 99ms/step - loss: 0.7828 - acc: 0.6952 - val_loss: 0.6897 - val_acc: 0.7364\n",
      "Epoch 38/50\n",
      "338/338 [==============================] - 33s 97ms/step - loss: 0.7685 - acc: 0.7028 - val_loss: 0.6764 - val_acc: 0.7587\n",
      "Epoch 39/50\n",
      "338/338 [==============================] - 34s 101ms/step - loss: 0.7434 - acc: 0.7152 - val_loss: 0.6072 - val_acc: 0.7764\n",
      "Epoch 40/50\n",
      "338/338 [==============================] - 35s 102ms/step - loss: 0.7467 - acc: 0.7061 - val_loss: 0.6802 - val_acc: 0.7389\n",
      "Epoch 41/50\n",
      "338/338 [==============================] - 36s 106ms/step - loss: 0.7301 - acc: 0.7222 - val_loss: 0.6151 - val_acc: 0.7723\n",
      "Epoch 42/50\n",
      "338/338 [==============================] - 37s 110ms/step - loss: 0.7427 - acc: 0.7189 - val_loss: 0.5971 - val_acc: 0.7818\n",
      "Epoch 43/50\n",
      "338/338 [==============================] - 38s 114ms/step - loss: 0.7212 - acc: 0.7191 - val_loss: 0.7294 - val_acc: 0.7327\n",
      "Epoch 44/50\n",
      "338/338 [==============================] - 41s 121ms/step - loss: 0.7488 - acc: 0.7105 - val_loss: 0.6490 - val_acc: 0.7493\n",
      "Epoch 45/50\n",
      "338/338 [==============================] - 40s 118ms/step - loss: 0.7596 - acc: 0.7155 - val_loss: 0.6164 - val_acc: 0.7689\n",
      "Epoch 46/50\n",
      "338/338 [==============================] - 53s 156ms/step - loss: 0.6981 - acc: 0.7365 - val_loss: 0.5870 - val_acc: 0.7790\n",
      "Epoch 47/50\n",
      "338/338 [==============================] - 41s 122ms/step - loss: 0.7132 - acc: 0.7125 - val_loss: 0.6205 - val_acc: 0.7591\n",
      "Epoch 48/50\n",
      "338/338 [==============================] - 42s 125ms/step - loss: 0.7217 - acc: 0.7250 - val_loss: 0.6096 - val_acc: 0.7591\n",
      "Epoch 49/50\n",
      "338/338 [==============================] - 45s 133ms/step - loss: 0.6794 - acc: 0.7350 - val_loss: 0.5891 - val_acc: 0.7621\n",
      "Epoch 50/50\n",
      "338/338 [==============================] - 41s 120ms/step - loss: 0.6930 - acc: 0.7352 - val_loss: 0.6113 - val_acc: 0.7587\n"
     ]
    }
   ],
   "source": [
    "#Entrenando el modelo:\n",
    "preddicted = model.fit_generator(\n",
    "    train_generator,\n",
    "    use_multiprocessing=True,\n",
    "    steps_per_epoch=len(train_generator.filenames) // batchSize,\n",
    "    epochs=numEpochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(train_generator.filenames) // batchSize\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9375"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTestBatch, yTestBatch = validation_generator.next()\n",
    "np.mean(1.0*(model.predict_classes(xTestBatch) == np.argmax(yTestBatch,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch sample: 0 accuracy: 0.75\n",
      "Batch sample: 1 accuracy: 0.5625\n",
      "Batch sample: 2 accuracy: 0.75\n",
      "Batch sample: 3 accuracy: 0.875\n",
      "Batch sample: 4 accuracy: 0.6875\n",
      "Batch sample: 5 accuracy: 0.875\n",
      "Batch sample: 6 accuracy: 0.8125\n",
      "Batch sample: 7 accuracy: 0.75\n",
      "Batch sample: 8 accuracy: 0.6875\n",
      "Batch sample: 9 accuracy: 0.6875\n",
      "Batch sample: 10 accuracy: 0.625\n",
      "Batch sample: 11 accuracy: 0.875\n",
      "Batch sample: 12 accuracy: 0.75\n",
      "Batch sample: 13 accuracy: 0.75\n",
      "Batch sample: 14 accuracy: 0.9375\n",
      "Batch sample: 15 accuracy: 0.8125\n",
      "0.76171875\n"
     ]
    }
   ],
   "source": [
    "listBatch = []\n",
    "for i in range(16):\n",
    "    xTestBatch, yTestBatch = validation_generator.next()\n",
    "    accuracy = np.mean(1.0*(model.predict_classes(xTestBatch) == np.argmax(yTestBatch,axis=1)))\n",
    "    listBatch.append(accuracy)\n",
    "    print(\"Batch sample: \"+ str(i)+\" accuracy: \"+ str(accuracy))\n",
    "print(np.mean(listBatch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejor Accuracy alcanzada: 76%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones:\n",
    "\n",
    "No se alcanzó el accuracy requerido, sin embargo, hubo mucha falta de experimentacion (intentar con batches de distinto tamaño, probar con más capas convolucionaes, optimizadores distintos, quizás incluir dropout para mas redundancia, etc.)\n",
    "\n",
    "A su vez, para una experiencia didactica mucho más completa, se debió utilizar un framework distinto a Keras, algo más de bajo nivel como TensorFlow o PyTorch. \n",
    "\n",
    "Pareciera ser que un hiperparametro definitivo en el entrenamiento fueron las Epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Convnet_MLII.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
