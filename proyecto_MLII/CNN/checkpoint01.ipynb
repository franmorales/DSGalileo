{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FFZyOKmYGFGp",
    "outputId": "4ec14141-7a23-4996-959d-64ac6ee2a543"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Librerias backend:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Librerias frontend:\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, Flatten, MaxPooling2D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_UhM4zk9B-1"
   },
   "source": [
    "# Presentacion del dataset y objetivo de la convnet:\n",
    "\n",
    "Se tiene un dataset contiendo imagenes de 16 piezas de lego distintas. El objetivo es lograr predecir al nombre de la pieza mostrada en la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omrlJYahHdsg"
   },
   "outputs": [],
   "source": [
    "#plt.imshow(\"/content/drive/My Drive/MLII/CNN/LEGO brick images/train/11214 Bush 3M friction with Cross axle/201706171006-0001.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YDCvHaU-JcTj"
   },
   "source": [
    "Para la implementacion del modelo se utilizará Keras, dada la simplicidad de implementacion y la flexibilidad en cuanto a la eleccion de la arquitectura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z6P4eRe1G6tP"
   },
   "source": [
    "# Architectura de la CNN:\n",
    "\n",
    "Se tomaran en cuenta las recomendaciones hechas en clase:\n",
    "\n",
    "* Se utilizara la funcion de activacion ReLu.\n",
    "* Se Utilizará Max Pooling (lo que hay \"mas importante\")\n",
    "* No se utiizará **dropaut**\n",
    "* Dado que el dataset consiste en imagenes renderizadas de piezas de lego rotadas, se evaluará la opcion de realizar aumentado de datos.\n",
    "* Se utilizará el optimizador Adam \n",
    "* Se utilizará un batch size de 64\n",
    "\n",
    "Las imagenes tiene un tamaño estandard de 72x72, siendo cada una de 3 canalaes. Por lo tanto, mi capa de entrada será de: 72x72x3.\n",
    "\n",
    "La capa convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R9DTJxOkJrvY"
   },
   "source": [
    "# Carga del dataset y preprocesamiento de las imagenes.\n",
    "\n",
    "Fuente: https://keras.io/preprocessing/image/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TjUp_T11GXh"
   },
   "outputs": [],
   "source": [
    "imageWidth = 72\n",
    "imageHeight = 72 \n",
    "imageChannel = 3\n",
    "testPorcen = 0.15\n",
    "batchSize = 64\n",
    "dataPath = 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2SFJDVp3dB7"
   },
   "source": [
    "Declaracion del generador para preprocesar las imagenes. Se tomara un 15% de datos para test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1IkrTF21Bed"
   },
   "outputs": [],
   "source": [
    "#Se utilizaran los valores por defecto de la generador:\n",
    "train_datagen = ImageDataGenerator(\n",
    "        validation_split=testPorcen, #Split argument for data division.\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ewd4VI1w3AJ-"
   },
   "source": [
    "Procedemos con la separacion de la data en Train y Test. **Debido a que especificamos el valor de validation_split en el generador anterior, ahora debemos especificar que datos son de validacion (test) y cuales son de train.**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "045x5Io83Oia",
    "outputId": "9aaa65f6-bec1-44ae-892f-f24149aa109f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5423 images belonging to 16 classes.\n",
      "Found 956 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        dataPath,\n",
    "        target_size=(imageHeight, imageWidth),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical', #Por defecto es categorical, sin embargo, no esta de más settearla manualmente.\n",
    "        subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        dataPath,\n",
    "        target_size=(imageHeight, imageWidth),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical', #Por defecto es categorical, sin embargo, no esta de más settearla manualmente.\n",
    "        subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ZBZCn4wEmQ5"
   },
   "source": [
    "Procedemos a aplicar los generadores para obtener nuestra deta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bm176I6Lknwo"
   },
   "source": [
    "# Creacion del modelo:\n",
    "\n",
    "Fuente: https://towardsdatascience.com/boost-your-cnn-image-classifier-performance-with-progressive-resizing-in-keras-a7d96da06e20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CbhpH0m2oKTI"
   },
   "outputs": [],
   "source": [
    "#Valores de la capa convolucional:\n",
    "filtersNumber = 8\n",
    "filterSize = 5\n",
    "pool_size = 3\n",
    "fully_connected_neurons = 64\n",
    "drop_out_factor = 0.6\n",
    "classes_out = 16 #numero de tipos de legos (neuronas de salida.)\n",
    "numEpochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "colab_type": "code",
    "id": "_JC54NJxpzl5",
    "outputId": "032a4e74-299c-4241-c815-bc23e554c41a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/FranciscoMorales/anaconda3/envs/tensor_flow_cpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/FranciscoMorales/anaconda3/envs/tensor_flow_cpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 68, 68, 64)        4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 18, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 255,888\n",
      "Trainable params: 255,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#Primera capa de convolución (se estan tomando en cuenta todas las recomendaciones indicadas: Funcion de activacion Relu, Mini Batch de 64)\n",
    "model.add(Conv2D(batchSize, input_shape=(imageHeight, imageWidth, imageChannel) , activation='relu', kernel_size=(filterSize, filterSize)  ))\n",
    "#Pooling, tomando en cuenta la recomendacion de utilizar MaxPooling:\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "\n",
    "#Segunda capa de convolucion:\n",
    "model.add(Conv2D(batchSize, input_shape=(imageHeight, imageWidth, imageChannel) , activation='relu', kernel_size=(filterSize, filterSize)  ))\n",
    "#Pooling para la segunda capa:\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "\n",
    "#Aplanado de la ultima capa de pooling con las respectivas caracteristicas para la parte \"fully connected\":\n",
    "model.add(Flatten())\n",
    "#Se utilizaran 64 neuronas en la etapa fully connected\n",
    "model.add(Dense(fully_connected_neurons, activation='relu'))\n",
    "#En esta etapa si se utilizará dropout, ya que equivale a un modelo MLP:\n",
    "model.add(Dropout(rate=drop_out_factor))\n",
    "#Se tienen 16 neuronas de salida, 1 para cada posible valor de la salida. Se utiliza Softmax puesto que necesitamos una probabiliad\n",
    "model.add(Dense(classes_out, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "bpeCrm6puMEx",
    "outputId": "491b9601-f637-4272-c450-eb739367f657"
   },
   "outputs": [],
   "source": [
    "#Compilando el modelo:\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 828
    },
    "colab_type": "code",
    "id": "CEawH8cvylD5",
    "outputId": "b1361ab8-db07-4075-f231-8caf8eafa09c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/FranciscoMorales/anaconda3/envs/tensor_flow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 55s 659ms/step - loss: 2.3547 - acc: 0.2089 - val_loss: 1.8632 - val_acc: 0.3463\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 54s 649ms/step - loss: 1.9664 - acc: 0.3115 - val_loss: 1.6603 - val_acc: 0.3838\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 55s 650ms/step - loss: 1.7549 - acc: 0.3843 - val_loss: 1.5033 - val_acc: 0.4199\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 59s 698ms/step - loss: 1.6247 - acc: 0.4165 - val_loss: 1.3267 - val_acc: 0.4963\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 58s 687ms/step - loss: 1.5124 - acc: 0.4569 - val_loss: 1.3174 - val_acc: 0.5351\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 56s 665ms/step - loss: 1.4172 - acc: 0.4784 - val_loss: 1.2662 - val_acc: 0.5289\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 57s 683ms/step - loss: 1.3250 - acc: 0.5042 - val_loss: 1.1684 - val_acc: 0.5521\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 57s 683ms/step - loss: 1.2638 - acc: 0.5329 - val_loss: 1.1569 - val_acc: 0.5603\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 57s 678ms/step - loss: 1.2004 - acc: 0.5538 - val_loss: 1.0487 - val_acc: 0.5880\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 74s 879ms/step - loss: 1.1631 - acc: 0.5628 - val_loss: 0.9996 - val_acc: 0.6379\n"
     ]
    }
   ],
   "source": [
    "#Entrenando el modelo:\n",
    "preddicted = model.fit_generator(\n",
    "    train_generator,\n",
    "    use_multiprocessing=True,\n",
    "    steps_per_epoch=len(train_generator.filenames) // batchSize,\n",
    "    epochs=numEpochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(train_generator.filenames) // batchSize\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch sample: 0 accuracy: 0.640625\n",
      "Batch sample: 1 accuracy: 0.578125\n",
      "Batch sample: 2 accuracy: 0.5625\n",
      "Batch sample: 3 accuracy: 0.65625\n",
      "Batch sample: 4 accuracy: 0.625\n",
      "Batch sample: 5 accuracy: 0.5625\n",
      "0.6041666666666666\n"
     ]
    }
   ],
   "source": [
    "listBatch = []\n",
    "for i in range(6):\n",
    "    xTestBatch, yTestBatch = validation_generator.next()\n",
    "    accuracy = np.mean(1.0*(model.predict_classes(xTestBatch) == np.argmax(yTestBatch,axis=1)))\n",
    "    listBatch.append(accuracy)\n",
    "    print(\"Batch sample: \"+ str(i)+\" accuracy: \"+ str(accuracy))\n",
    "print(np.mean(listBatch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se obtiene un accuracy del 60% en promedio, por lo que se modificara el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparametros a resaltar:\n",
    "* Batch size de 64\n",
    "* Tamaño de los filtros en las capas convolucionales: 5x5\n",
    "* Epochs: 10\n",
    "* Optimizador: Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Convnet_MLII.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
