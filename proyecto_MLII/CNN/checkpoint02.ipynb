{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FFZyOKmYGFGp",
    "outputId": "4ec14141-7a23-4996-959d-64ac6ee2a543"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Librerias backend:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "# Librerias frontend:\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, Flatten, MaxPooling2D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_UhM4zk9B-1"
   },
   "source": [
    "# Presentacion del dataset y objetivo de la convnet:\n",
    "\n",
    "Se tiene un dataset contiendo imagenes de 16 piezas de lego distintas. El objetivo es lograr predecir al nombre de la pieza mostrada en la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omrlJYahHdsg"
   },
   "outputs": [],
   "source": [
    "#plt.imshow(\"/content/drive/My Drive/MLII/CNN/LEGO brick images/train/11214 Bush 3M friction with Cross axle/201706171006-0001.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YDCvHaU-JcTj"
   },
   "source": [
    "Para la implementacion del modelo se utilizará Keras, dada la simplicidad de implementacion y la flexibilidad en cuanto a la eleccion de la arquitectura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z6P4eRe1G6tP"
   },
   "source": [
    "# Architectura de la CNN:\n",
    "\n",
    "Se tomaran en cuenta las recomendaciones hechas en clase:\n",
    "\n",
    "* Se utilizara la funcion de activacion ReLu.\n",
    "* Se Utilizará Max Pooling (lo que hay \"mas importante\")\n",
    "* No se utiizará **dropaut**\n",
    "* Dado que el dataset consiste en imagenes renderizadas de piezas de lego rotadas, se evaluará la opcion de realizar aumentado de datos.\n",
    "* Se utilizará el optimizador Adam \n",
    "* Se utilizará un batch size de 64\n",
    "\n",
    "Las imagenes tiene un tamaño estandard de 72x72, siendo cada una de 3 canalaes. Por lo tanto, mi capa de entrada será de: 72x72x3.\n",
    "\n",
    "La capa convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R9DTJxOkJrvY"
   },
   "source": [
    "# Carga del dataset y preprocesamiento de las imagenes.\n",
    "\n",
    "Fuente: https://keras.io/preprocessing/image/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TjUp_T11GXh"
   },
   "outputs": [],
   "source": [
    "imageWidth = 72\n",
    "imageHeight = 72 \n",
    "imageChannel = 3\n",
    "testPorcen = 0.15\n",
    "batchSize = 32\n",
    "dataPath = 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2SFJDVp3dB7"
   },
   "source": [
    "Declaracion del generador para preprocesar las imagenes. Se tomara un 15% de datos para test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1IkrTF21Bed"
   },
   "outputs": [],
   "source": [
    "#Se utilizaran los valores por defecto de la generador:\n",
    "train_datagen = ImageDataGenerator(\n",
    "        validation_split=testPorcen, #Split argument for data division.\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ewd4VI1w3AJ-"
   },
   "source": [
    "Procedemos con la separacion de la data en Train y Test. **Debido a que especificamos el valor de validation_split en el generador anterior, ahora debemos especificar que datos son de validacion (test) y cuales son de train.**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "045x5Io83Oia",
    "outputId": "9aaa65f6-bec1-44ae-892f-f24149aa109f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5423 images belonging to 16 classes.\n",
      "Found 956 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        dataPath,\n",
    "        target_size=(imageHeight, imageWidth),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical', #Por defecto es categorical, sin embargo, no esta de más settearla manualmente.\n",
    "        subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        dataPath,\n",
    "        target_size=(imageHeight, imageWidth),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical', #Por defecto es categorical, sin embargo, no esta de más settearla manualmente.\n",
    "        subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ZBZCn4wEmQ5"
   },
   "source": [
    "Procedemos a aplicar los generadores para obtener nuestra deta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bm176I6Lknwo"
   },
   "source": [
    "# Creacion del modelo:\n",
    "\n",
    "Fuente: https://towardsdatascience.com/boost-your-cnn-image-classifier-performance-with-progressive-resizing-in-keras-a7d96da06e20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CbhpH0m2oKTI"
   },
   "outputs": [],
   "source": [
    "#Valores de la capa convolucional:\n",
    "filtersNumber = 8\n",
    "filterSize = 5\n",
    "pool_size = 3\n",
    "fully_connected_neurons = 64\n",
    "drop_out_factor = 0.6\n",
    "classes_out = 16 #numero de tipos de legos (neuronas de salida.)\n",
    "numEpochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "colab_type": "code",
    "id": "_JC54NJxpzl5",
    "outputId": "032a4e74-299c-4241-c815-bc23e554c41a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/FranciscoMorales/anaconda3/envs/tensor_flow_cpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 68, 68, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 18, 18, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 102,896\n",
      "Trainable params: 102,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#Primera capa de convolución (se estan tomando en cuenta todas las recomendaciones indicadas: Funcion de activacion Relu, Mini Batch de 64)\n",
    "model.add(Conv2D(batchSize, input_shape=(imageHeight, imageWidth, imageChannel) , activation='relu', kernel_size=(filterSize, filterSize)  ))\n",
    "#Pooling, tomando en cuenta la recomendacion de utilizar MaxPooling:\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "\n",
    "#Segunda capa de convolucion:\n",
    "model.add(Conv2D(batchSize, input_shape=(imageHeight, imageWidth, imageChannel) , activation='relu', kernel_size=(filterSize, filterSize)  ))\n",
    "#Pooling para la segunda capa:\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "\n",
    "#Aplanado de la ultima capa de pooling con las respectivas caracteristicas para la parte \"fully connected\":\n",
    "model.add(Flatten())\n",
    "#Se utilizaran 64 neuronas en la etapa fully connected\n",
    "model.add(Dense(fully_connected_neurons, activation='relu'))\n",
    "#En esta etapa si se utilizará dropout, ya que equivale a un modelo MLP:\n",
    "model.add(Dropout(rate=drop_out_factor))\n",
    "#Se tienen 16 neuronas de salida, 1 para cada posible valor de la salida. Se utiliza Softmax puesto que necesitamos una probabiliad\n",
    "model.add(Dense(classes_out, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "bpeCrm6puMEx",
    "outputId": "491b9601-f637-4272-c450-eb739367f657"
   },
   "outputs": [],
   "source": [
    "#Compilando el modelo:\n",
    "model.compile(\n",
    "    optimizer=RMSprop(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 828
    },
    "colab_type": "code",
    "id": "CEawH8cvylD5",
    "outputId": "b1361ab8-db07-4075-f231-8caf8eafa09c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/FranciscoMorales/anaconda3/envs/tensor_flow_cpu/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "169/169 [==============================] - 37s 217ms/step - loss: 2.3320 - acc: 0.2234 - val_loss: 1.7630 - val_acc: 0.3692\n",
      "Epoch 2/20\n",
      "169/169 [==============================] - 42s 246ms/step - loss: 1.8791 - acc: 0.3479 - val_loss: 1.4978 - val_acc: 0.4387\n",
      "Epoch 3/20\n",
      "169/169 [==============================] - 41s 242ms/step - loss: 1.6722 - acc: 0.4065 - val_loss: 1.3927 - val_acc: 0.4584\n",
      "Epoch 4/20\n",
      "169/169 [==============================] - 43s 255ms/step - loss: 1.4885 - acc: 0.4556 - val_loss: 1.2734 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "169/169 [==============================] - 50s 295ms/step - loss: 1.4165 - acc: 0.4802 - val_loss: 1.2218 - val_acc: 0.5325\n",
      "Epoch 6/20\n",
      "169/169 [==============================] - 55s 324ms/step - loss: 1.3247 - acc: 0.5120 - val_loss: 1.1724 - val_acc: 0.5702\n",
      "Epoch 7/20\n",
      "169/169 [==============================] - 51s 303ms/step - loss: 1.2440 - acc: 0.5366 - val_loss: 1.1320 - val_acc: 0.5654\n",
      "Epoch 8/20\n",
      "169/169 [==============================] - 54s 318ms/step - loss: 1.2031 - acc: 0.5566 - val_loss: 1.0634 - val_acc: 0.5984\n",
      "Epoch 9/20\n",
      "169/169 [==============================] - 60s 353ms/step - loss: 1.1230 - acc: 0.5799 - val_loss: 0.9969 - val_acc: 0.6179\n",
      "Epoch 10/20\n",
      "169/169 [==============================] - 57s 339ms/step - loss: 1.0650 - acc: 0.6107 - val_loss: 1.0114 - val_acc: 0.6061\n",
      "Epoch 11/20\n",
      "169/169 [==============================] - 66s 388ms/step - loss: 1.0340 - acc: 0.6099 - val_loss: 0.9508 - val_acc: 0.6412\n",
      "Epoch 12/20\n",
      "169/169 [==============================] - 57s 335ms/step - loss: 0.9940 - acc: 0.6336 - val_loss: 0.9468 - val_acc: 0.6350\n",
      "Epoch 13/20\n",
      "169/169 [==============================] - 57s 339ms/step - loss: 0.9506 - acc: 0.6443 - val_loss: 0.9032 - val_acc: 0.6551\n",
      "Epoch 14/20\n",
      "169/169 [==============================] - 48s 281ms/step - loss: 0.9496 - acc: 0.6537 - val_loss: 0.9316 - val_acc: 0.6437\n",
      "Epoch 15/20\n",
      "169/169 [==============================] - 53s 314ms/step - loss: 0.9083 - acc: 0.6573 - val_loss: 0.8391 - val_acc: 0.6757\n",
      "Epoch 16/20\n",
      "169/169 [==============================] - 54s 318ms/step - loss: 0.8905 - acc: 0.6656 - val_loss: 0.7855 - val_acc: 0.6802\n",
      "Epoch 17/20\n",
      "169/169 [==============================] - 54s 321ms/step - loss: 0.8665 - acc: 0.6746 - val_loss: 0.8091 - val_acc: 0.6811\n",
      "Epoch 18/20\n",
      "169/169 [==============================] - 55s 323ms/step - loss: 0.8106 - acc: 0.7002 - val_loss: 0.8334 - val_acc: 0.6846\n",
      "Epoch 19/20\n",
      "169/169 [==============================] - 61s 358ms/step - loss: 0.8313 - acc: 0.6935 - val_loss: 0.7368 - val_acc: 0.7234\n",
      "Epoch 20/20\n",
      "169/169 [==============================] - 54s 320ms/step - loss: 0.8163 - acc: 0.7005 - val_loss: 0.7157 - val_acc: 0.7153\n"
     ]
    }
   ],
   "source": [
    "#Entrenando el modelo:\n",
    "preddicted = model.fit_generator(\n",
    "    train_generator,\n",
    "    use_multiprocessing=True,\n",
    "    steps_per_epoch=len(train_generator.filenames) // batchSize,\n",
    "    epochs=numEpochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(train_generator.filenames) // batchSize\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84375"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTestBatch, yTestBatch = validation_generator.next()\n",
    "np.mean(1.0*(model.predict_classes(xTestBatch) == np.argmax(yTestBatch,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch sample: 0 accuracy: 0.8125\n",
      "Batch sample: 1 accuracy: 0.78125\n",
      "Batch sample: 2 accuracy: 0.71875\n",
      "Batch sample: 3 accuracy: 0.875\n",
      "Batch sample: 4 accuracy: 0.71875\n",
      "Batch sample: 5 accuracy: 0.78125\n",
      "Batch sample: 6 accuracy: 0.65625\n",
      "Batch sample: 7 accuracy: 0.625\n",
      "Batch sample: 8 accuracy: 0.71875\n",
      "Batch sample: 9 accuracy: 0.65625\n",
      "0.734375\n"
     ]
    }
   ],
   "source": [
    "listBatch = []\n",
    "for i in range(10):\n",
    "    xTestBatch, yTestBatch = validation_generator.next()\n",
    "    accuracy = np.mean(1.0*(model.predict_classes(xTestBatch) == np.argmax(yTestBatch,axis=1)))\n",
    "    listBatch.append(accuracy)\n",
    "    print(\"Batch sample: \"+ str(i)+\" accuracy: \"+ str(accuracy))\n",
    "print(np.mean(listBatch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se obtiene un accuracy del 73% en promedio, por lo que se modificara el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparametros a resaltar:\n",
    "* Batch size de 32\n",
    "* Tamaño de los filtros en las capas convolucionales: 5x5\n",
    "* Epochs: 20\n",
    "* Optimizador: RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Convnet_MLII.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
